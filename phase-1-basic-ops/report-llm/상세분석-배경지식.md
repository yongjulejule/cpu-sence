# CPU 연산 결과 해석을 위한 상세 배경지식

## 1. CPU 아키텍처 기초 지식

### 파이프라인 구조

- **정의**: 명령어 처리를 여러 단계로 나누고 동시에 서로 다른 명령어의 다른 단계를 처리하는 CPU 설계 방식
- **단계**: 일반적으로 Fetch(명령어 가져오기) → Decode(해석) → Execute(실행) → Memory(메모리 접근) → Write Back(결과 저장) 과정을 거침
- **이점**: 한 명령어가 실행될 때 다음 명령어의 준비를 동시에 진행하여 처리량 증가
- **위험요소**: 데이터 의존성, 제어 의존성(분기) 등으로 파이프라인이 효율을 잃을 수 있음
- **실무 영향**: 조건문이 많거나 예측 불가능한 코드는 파이프라인 효율을 떨어뜨림

### 슈퍼스칼라 아키텍처

- **정의**: 여러 개의 파이프라인을 병렬로 배치하여 한 클럭 사이클에 여러 명령어를 동시에 실행
- **구성**: 여러 개의 실행 유닛(ALU, FPU 등)을 가지고 있어 독립적인 연산 동시 처리
- **투기적 실행**: 명령어를 미리 실행해두고 필요하면 결과를 사용하는 최적화 방식
- **비순차적 실행**: 명령어들을 원래 순서와 다르게 실행하여 리소스 사용 극대화
- **실무 영향**: IPC가 1보다 높게 나오는 이유, 코드가 병렬화 가능할수록 성능 향상

### 분기 예측

- **정의**: 조건문의 실행 결과를 미리 예측하여 파이프라인을 채우는 CPU 기능
- **정적 예측**: 항상 분기를 취한다/취하지 않는다는 단순 규칙 기반 예측
- **동적 예측**: 이전 실행 패턴을 기록하는 분기 예측 버퍼(BHT) 사용
- **예측 성공률**: 현대 CPU는 보통 90-95% 이상의 높은 예측 성공률 보임
- **실무 영향**: 예측 불가능한 if 문은 성능 저하 유발, 규칙적인 패턴이 성능에 유리

### 캐시 계층

- **L1 캐시**: CPU 코어에 가장 가까운 캐시, 보통 32KB~64KB, 접근 지연 ~1ns
- **L2 캐시**: 중간 계층 캐시, 보통 256KB~1MB, 접근 지연 ~4ns
- **L3 캐시**: 여러 코어가 공유하는 캐시, 보통 수 MB~수십 MB, 접근 지연 ~10ns
- **메인 메모리(RAM)**: 캐시보다 훨씬 느림, 접근 지연 ~100ns
- **캐시 라인**: 보통 64바이트 단위로 데이터 전송, 연속된 메모리가 더 효율적
- **실무 영향**: 메모리 지역성(인접한 데이터 접근)이 높은 알고리즘이 캐시 효율 증가

## 2. 성능 측정 지표 이해

### IPC(Instructions Per Cycle)

- **정의**: 한 클럭 사이클 동안 평균적으로 실행된 명령어 수
- **계산 방법**: 총 실행 명령어 수 ÷ 총 사이클 수
- **정상 범위**: 일반적으로 0.5~3.0 사이 (CPU 아키텍처에 따라 다름)
- **높은 IPC 의미**: 파이프라인과 실행 유닛이 효율적으로 활용됨
- **낮은 IPC 의미**: 메모리 지연, 분기 미스, 데이터 의존성 등의 병목 존재
- **실무 영향**: IPC가 높을수록 동일 클럭에서 더 많은 연산 처리 가능

### CPI(Cycles Per Instruction)

- **정의**: 한 명령어를 실행하는 데 필요한 평균 클럭 사이클 수 (IPC의 역수)
- **계산 방법**: 총 사이클 수 ÷ 총 실행 명령어 수
- **좋은 값**: 낮을수록 효율적 (1 미만이 이상적)
- **영향 요소**: 메모리 접근, 분기, 긴 연산 등이 CPI를 높임
- **실무 영향**: CPI가 낮은 코드는 같은 클럭 속도의 CPU에서 더 빠르게 실행됨

### 스톨(Stall)

- **프론트엔드 스톨**: 명령어 fetch/decode 과정의 지연, 주로 명령어 캐시 미스나 분기 예측 실패 시 발생
- **백엔드 스톨**: 명령어 실행 과정의 지연, 주로 데이터 의존성이나 메모리 접근 지연 시 발생
- **구조적 스톨**: 필요한 하드웨어 리소스(실행 유닛)가 모두 사용 중일 때 발생
- **데이터 스톨**: 이전 명령어의 결과가 필요한 경우 발생하는 지연
- **측정 방법**: `stalled-cycles-frontend`, `stalled-cycles-backend` 메트릭으로 측정
- **실무 영향**: 높은 스톨 비율은 CPU 사용 효율성 저하를 의미

### 브랜치 미스

- **정의**: CPU의 분기 예측이 틀렸을 때 발생하는 현상
- **결과**: 파이프라인 비우기(flush) 발생, 이미 실행 중이던 명령어 버리고 새로 시작
- **비용**: 현대 CPU에서 분기 미스 한 번에 약 10-20 사이클 손실
- **미스 비율**: 일반적으로 총 분기 중 1-5%의 미스율이 정상적
- **측정 방법**: `branch-misses` ÷ `branches` × 100%
- **실무 영향**: 예측 불가능한 조건문이 많은 코드(예: 해시 테이블 충돌 처리)는 성능 저하

### 페이지 폴트

- **정의**: 프로세스가 접근하려는 메모리 페이지가 물리 메모리에 없을 때 발생
- **종류**:
  - **Minor Fault**: 페이지가 이미 메모리에 있지만 페이지 테이블에 매핑되지 않은 경우
  - **Major Fault**: 디스크에서 페이지를 읽어와야 하는 경우 (매우 비쌈)
- **비용**: Minor 수백 사이클, Major는 밀리초 단위의 지연 발생
- **측정 방법**: `page-faults` 메트릭으로 측정
- **실무 영향**: 대량의 메모리를 새로 할당하는 코드는 페이지 폴트가 많이 발생

## 3. 시간 측정 관련 개념

### Wall Time(실제 시간)

- **정의**: 프로그램 시작부터 종료까지 실제 경과된 시계 시간
- **측정 단위**: 초(s), 밀리초(ms) 등
- **특징**: 다른 프로세스의 영향, I/O 대기 시간, 스케줄링 지연 등 모두 포함
- **명령어**: `time` 명령의 `real` 출력, `Elapsed (wall clock) time`
- **실무 영향**: 사용자가 실제로 체감하는 응답 시간이므로 가장 중요한 지표

### User Time(사용자 시간)

- **정의**: 프로세스가 사용자 모드에서 CPU를 실제로 사용한 시간
- **포함 내용**: 프로그램 코드 실행, 라이브러리 호출 등 (커널 모드 제외)
- **특징**: 여러 코어/스레드를 사용하면 Wall Time보다 클 수 있음
- **명령어**: `time` 명령의 `user` 출력, `User time (seconds)`
- **실무 영향**: 실제 연산 처리에 소요된 CPU 시간으로, 알고리즘 효율성 판단에 유용

### System Time(시스템 시간)

- **정의**: 프로세스가 커널 모드에서 시스템 콜을 처리하는 데 사용된 시간
- **포함 내용**: 파일 I/O, 네트워크 통신, 메모리 할당 등 OS 서비스 호출
- **특징**: 높은 System Time은 I/O 또는 시스템 콜 의존도가 높음을 의미
- **명령어**: `time` 명령의 `sys` 출력, `System time (seconds)`
- **실무 영향**: 높은 비율은 I/O나 시스템 리소스 사용 최적화 필요성 시사

### CPU 점유율

- **정의**: 프로세스가 실행 중에 CPU를 사용한 비율
- **계산 방법**: (User Time + System Time) ÷ Wall Time × 100%
- **해석**:
  - **100%**: 단일 코어를 완전히 사용
  - **>100%**: 멀티코어/멀티스레드 활용 (예: 200%는 2개 코어 완전 활용)
  - **<100%**: I/O 대기 또는 리소스 경합 존재
- **명령어**: `time -v` 출력의 `Percent of CPU this job got`
- **실무 영향**: 낮은 CPU 점유율은 I/O 바운드, 높은 점유율은 CPU 바운드 작업 의미

## 4. 시스템 리소스 개념

### 가상 메모리와 물리 메모리

- **가상 메모리**: 프로세스가 보는 논리적 주소 공간, 연속적이고 독립적
- **물리 메모리**: 실제 RAM에 존재하는 메모리, 비연속적이고 공유됨
- **페이지**: 일반적으로 4KB 크기의 메모리 블록 단위, 가상-물리 매핑의 기본 단위
- **페이징**: 가상 메모리를 물리 메모리에 매핑하는 과정, MMU(Memory Management Unit)가 담당
- **스왑**: 물리 메모리 부족 시 디스크에 일부 페이지를 임시 저장하는 메커니즘
- **실무 영향**: 메모리 사용량이 많은 애플리케이션은 페이지 폴트와 스왑으로 성능 저하 가능

### 시스템 콜

- **정의**: 프로세스가 커널 기능을 요청하는 인터페이스
- **작동 방식**:
  1. 사용자 모드에서 커널 모드로 전환 (컨텍스트 스위치)
  2. 커널에서 요청 기능 수행
  3. 커널 모드에서 사용자 모드로 돌아옴
- **비용**: 모드 전환으로 인해 수백~수천 CPU 사이클 소요
- **예시**: open(), read(), write(), mmap(), brk() 등
- **실무 영향**: 빈번한 시스템 콜은 오버헤드 증가, 배치 처리로 줄이는 것이 유리

### 메모리 할당 방식

- **brk()/sbrk()**: 프로세스의 힙 영역 끝점(break point)을 확장하는 시스템 콜
  - **용도**: 작은 크기의 메모리 할당(malloc 내부에서 사용)
  - **특징**: 연속된 메모리 공간 할당
- **mmap()**: 파일이나 장치를 메모리에 매핑하는 시스템 콜

  - **용도**: 큰 메모리 블록 할당, 파일 매핑, 공유 메모리
  - **특징**: 별도의 메모리 영역 사용, 페이지 단위로 관리

- **malloc() 내부 작동**:

  - 작은 크기: 미리 할당된 힙 메모리에서 고속 할당 (brk 기반)
  - 큰 크기: mmap() 시스템 콜로 별도 메모리 영역 할당
  - **Jemalloc/tcmalloc**: 스레드별 캐시와 크기별 풀링으로 최적화된 할당자

- **실무 영향**: 빈번한 메모리 할당/해제는 성능 저하 유발, 객체 풀 패턴으로 개선 가능

### 컨텍스트 스위치

- **정의**: CPU가 다른 프로세스나 스레드로 전환할 때 상태를 저장하고 복원하는 과정
- **비용 구성**:
  - CPU 레지스터 저장/복원
  - 캐시 무효화 및 재적재
  - TLB(Translation Lookaside Buffer) 비우기
  - 파이프라인 플러시
- **발생 상황**: 스케줄링, 시스템 콜, I/O 대기, 인터럽트 처리
- **전형적 비용**: 1-10 마이크로초 (수천 사이클, CPU 종류와 OS에 따라 다름)
- **측정 지표**: `context-switches`, `cpu-migrations`
- **실무 영향**: 빈번한 컨텍스트 스위치는 CPU 사용 효율 저하, 비동기/이벤트 기반 설계로 개선 가능

## 5. 컴파일러와 최적화

### 상수 폴딩(Constant Folding)

- **정의**: 컴파일 시점에 결과가 상수인 연산을 미리 계산하는 최적화
- **예시**: `int x = 5 * 60;` → `int x = 300;`으로 컴파일
- **확장**: 상수 전파(constant propagation)와 함께 더 복잡한 최적화 가능
- **효과**: 런타임에 불필요한 연산 제거
- **실무 영향**: 재귀 함수의 결과가 컴파일 시간에 결정되면 완전히 최적화될 수 있음

### 함수 인라인화

- **정의**: 함수 호출 대신 함수 본문 코드를 직접 삽입하는 최적화
- **이점**:
  - 함수 호출 오버헤드(스택 프레임 생성, 점프) 제거
  - 컨텍스트에 맞는 추가 최적화 가능
- **단점**: 코드 크기 증가로 인한 명령어 캐시 효율성 저하 가능
- **인라인 대상**: 작고 자주 호출되는 함수가 이상적
- **실무 영향**: 핫스팟 함수를 인라인화하면 성능 향상, JavaScript의 JIT도 비슷한 최적화 수행

### 루프 언롤링

- **정의**: 반복문 본체를 여러 번 복제하여 반복 횟수를 줄이는 최적화
- **예시**:

  ```c
  // 원본
  for(int i=0; i<100; i++) { sum += array[i]; }

  // 언롤링 후
  for(int i=0; i<100; i+=4) {
    sum += array[i];
    sum += array[i+1];
    sum += array[i+2];
    sum += array[i+3];
  }
  ```

- **이점**: 루프 카운터 증가 및 조건 검사 횟수 감소, 병렬 명령어 실행 기회 증가
- **트레이드오프**: 코드 크기 증가 vs 성능 향상
- **실무 영향**: 핫스팟 루프에서 유용, 벡터화와 결합 시 더 효과적

### 꼬리 재귀 최적화

- **정의**: 재귀 호출이 함수의 마지막 연산인 경우 이를 반복문으로 변환하는 최적화
- **예시**:

  ```c
  // 꼬리 재귀
  int factorial(int n, int acc) {
    if (n <= 1) return acc;
    return factorial(n-1, n*acc);  // 꼬리 위치의 재귀 호출
  }

  // 최적화 후 (컴파일러 내부 변환)
  int factorial(int n, int acc) {
    while (n > 1) {
      acc = n * acc;
      n = n - 1;
    }
    return acc;
  }
  ```

- **이점**: 스택 오버플로우 방지, 스택 프레임 재사용으로 메모리 효율 향상
- **지원**: 모든 컴파일러가 지원하는 것은 아님 (GCC는 `-O2` 이상에서 지원)
- **실무 영향**: 실험 결과에서 recursion_tail.c의 높은 IPC(33.98)는 이 최적화 덕분

## 6. DevOps 관련 지식

### vCPU 개념

- **정의**: 클라우드 환경에서 제공하는 가상화된 CPU 유닛
- **물리 코어와의 관계**:
  - 일반적으로 1 vCPU ≈ 1 하이퍼스레드 (물리 코어의 일부)
  - 클라우드 제공자마다 다를 수 있음 (AWS의 경우 인스턴스 유형에 따라 다름)
- **CPU 점유율**: 100% vCPU 사용은 할당된 가상 코어의 최대 성능을 의미
- **버스트 가능 인스턴스**: AWS t2/t3와 같은 인스턴스는 일시적으로 기준 성능 초과 가능
- **실무 영향**: QPS당 필요한 vCPU 계산 시 실제 측정값과 안전 마진 고려 필요

### 컨테이너 리소스 제한

- **CPU 제한**:
  - **Docker**: `--cpus=1.5` (1.5 코어로 제한)
  - **Kubernetes**: `resources.limits.cpu: "1.5"` (1.5 코어로 제한)
- **메모리 제한**:
  - **Docker**: `--memory=1g` (1GB로 제한)
  - **Kubernetes**: `resources.limits.memory: "1Gi"` (1GiB로 제한)
- **CPU 요청과 제한의 차이**:
  - **요청(requests)**: 최소 보장 자원, 스케줄링 기준
  - **제한(limits)**: 최대 사용 가능 자원, 초과 시 스로틀링
- **OOMKilled**: 메모리 제한 초과 시 컨테이너 강제 종료
- **실무 영향**: 제한이 너무 낮으면 성능 저하, 너무 높으면 리소스 낭비 가능

### QPS와 CPU 사용량의 관계

- **선형 관계**: 일반적으로 낮은 부하에서는 QPS와 CPU 사용량이 선형 비례
- **포화 지점**: 특정 QPS 이상에서는 CPU가 100%에 도달하여 처리량 정체
- **계산 방법**:
  - 단일 요청 CPU 시간 = User Time + System Time
  - 초당 최대 처리량 = 1초 ÷ 단일 요청 CPU 시간
  - 필요 vCPU 수 = 목표 QPS ÷ (단일 vCPU 최대 처리량 × 안전계수)
- **안전 계수**: 보통 0.7~0.8 (70-80% 활용도 목표)
- **실무 영향**: 성능 테스트 기반으로 필요 vCPU 산정, 자동 확장 정책 수립에 활용

### 클라우드 인스턴스 유형

- **범용(T 시리즈)**:
  - **특징**: 가변적 워크로드, 버스트 성능 지원
  - **용도**: 개발 환경, 웹 서버, 소규모 DB
  - **예시**: AWS t3.medium(2 vCPU, 4GB)
- **컴퓨팅 최적화(C 시리즈)**:
  - **특징**: 고성능 CPU, 높은 CPU:메모리 비율
  - **용도**: 배치 처리, 과학 계산, 게임 서버, 트래픽 높은 웹 서버
  - **예시**: AWS c5.xlarge(4 vCPU, 8GB)
- **메모리 최적화(R 시리즈)**:
  - **특징**: 대용량 메모리, 낮은 CPU:메모리 비율
  - **용도**: 인메모리 DB, 캐싱 서버, 데이터 분석
  - **예시**: AWS r5.large(2 vCPU, 16GB)
- **실무 영향**: 워크로드 특성에 맞는 인스턴스 선택으로 비용 최적화 가능

## 7. 기본 해석 방법론

### 기준 설정

- **단위 연산 설정**: 개별 API 요청이나 특정 기능 단위로 구분
- **기준 측정값 선정**: 단순 루프나 정수 연산 등 기본 연산을 기준점으로 설정
- **상대적 비용 계산**: 다른 복잡한 연산의 비용을 기준 연산 대비 배수로 표현
- **절대 시간 측정**: Wall Time, User Time, System Time 기록
- **실무 영향**: 기준점이 있으면 새로운 기능 추가 시 리소스 요구사항 예측 용이

### 병목 지점 식별

- **IPC 분석**: 낮은 IPC(1.0 미만)는 파이프라인 비효율 의미
- **스톨 분석**:
  - 높은 프론트엔드 스톨 → 명령어 캐시 미스, 분기 예측 실패
  - 높은 백엔드 스톨 → 데이터 캐시 미스, 메모리 지연
- **캐시 미스**: 높은 캐시 미스율은 메모리 접근 패턴 최적화 필요성 시사
- **시스템 시간 비율**: 높은 System Time은 I/O나 시스템 콜 최적화 필요성 시사
- **실무 영향**: 병목 지점 파악으로 최적화 우선순위 결정 가능

### CPU 사용량 계산

- **단위 연산당 CPU 시간**: `User Time + System Time`
- **요청당 CPU 사용률**: `(단위 연산 CPU 시간 ÷ Wall Time) × 100%`
- **vCPU 사용량 추정**: 요청당 CPU 시간(초) × QPS = 필요 vCPU 수
- **멀티코어 활용도**: CPU 바운드 작업은 코어 수에 비례하여 처리량 증가
- **실무 영향**: API 서버의 리소스 요구사항 예측에 직접 활용 가능

### 확장성 예측

- **선형 확장**: vCPU 수를 늘릴 때 처리량이 비례하여 증가하는지 검증
- **스케일 아웃 vs 스케일 업**:
  - 작은 인스턴스 여러 개 vs 큰 인스턴스 소수
  - CPU 바운드 작업은 보통 둘 다 비슷한 효율성
  - I/O 바운드 작업은 스케일 아웃이 유리할 수 있음
- **Amdahl의 법칙**: 병렬화 가능 부분이 전체 성능 향상 한계 결정
- **실무 영향**: 오토스케일링 정책 수립, 최대 확장 한계 예측에 활용

### 부하 예상

- **트래픽 패턴 분석**: 일반/피크 트래픽, 일/주/월 패턴, 계절성
- **예상 QPS 계산**:
  - 일평균 요청 수 ÷ 86400초 = 평균 QPS
  - 피크 시간대 증폭 계수(보통 2~5배) 적용
- **리소스 필요량 계산**: 예상 QPS × 요청당 CPU 시간 × 안전계수(1.2~1.5)
- **성장 계획**: 향후 6개월~1년 예상 성장률 반영
- **실무 영향**: 클라우드 리소스 사전 확보, 비용 예측, 용량 계획에 활용
